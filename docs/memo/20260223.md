

## 現行の機能
### 現行の機能
- 日々のポストの登録
  - １記事１００文字程度、１０件程度、タイトル、コンテンツ、メモを想定、４年分ほどあり
- まとめて、１週間分のポストをAIで整形、タグの付与など
  - AIはGoogleAIStudio経由で問い合わせ、結果を画面表示
    - 上限設定、一日１０件、７日分なので、７０件想定なので、２０件づつ３件実施、５分タイムラグあり
  - 実施した記録、ポスト単位で、記録される。原文、AI評価（変更なし）、AI評価（変更有）
  - AIに送信するのはプロンプト自体と、分析したいデータ、タグの候補説明を生成AIに送信
- 付与されたタグをもとに分析

### 現行の環境
- NextJS+Vercel
- Supabase(認証、RDB) ：日々のポストの記事自体、タグのデータ
- Turso(SQLite)：ログ、AI送信前後でのデータなど

## 実施したいこと
### 要件
- 定期的に動く処理を裏で実装したい
  - １分単位で、Postの状況確認、AIでの生成未実施のもについては、AIへの送信対象とする
  - AIでの作業中なら、処理停止、1分後に再度実施するイメージ
  - UI側では、AI結果受領していもの、ポスト単位で、確認出来て、それでOKなら登録できる
  - 一度AIへ問い合わせたものは問い合わせないようにしたい
- 処理のログはのコストこと
- メールなどで、定期的に特定のメールアドレスに通知を行う。
- 週単位で、ユーザーのポストを確認して、AIに特記すべきことはないかなど問い合わせて、結果を保存する機能をもつ
  - 上記データは別のスペースに保存して、そこで確認できるようにする。
- ホストはVercel以外にして、APIで公開する形を想定、UIは最適減にする


詳細な構成案をありがとうございます。
「4年分のデータがある」「TursoとSupabaseを併用」「1分おきのポーリング」という具体的なスケールが見えてきました。

結論から申し上げますと、**「コスト」と「AI（Google AI Studio）との相性」を考えると、Google Cloud Run (FastAPI)** が最も合理的です。

---

## 1. コストシミュレーション

### Google Cloud Run (FastAPI)

* **計算コスト:** Cloud Runの無料枠は非常に大きく、1回の実行（DB確認のみで終了する場合）は数ミリ秒で終わります。AI送信時のみ数秒動く計算ですが、**月額  ドル未満（ほぼ無料枠内）**で収まる可能性が高いです。
* **Google AI Studioとの親和性:** 同じGoogle Cloudのエコシステム内（または近接）にあるため、認証やレイテンシ、将来的なVertex AIへの移行がスムーズです。
* **Cloud Scheduler:** 定期実行のトリガーに月額  ドル程度かかります。

### Cloudflare Workers (Hono)

* **計算コスト:** リクエスト回数課金なのでこちらもほぼ無料です。
* **懸念点:** Tursoへの接続は得意ですが、Supabase（PostgreSQL）への接続には `Hyperdrive` などの設定や追加コストがかかる場合があります。また、AI StudioのAPIレスポンスが30秒を超えると標準プランではタイムアウトします。

---

## 2. 推奨するアーキテクチャ

FastAPIを「ジョブ・ワーカー」として使い、Tursoを「進捗管理・排他制御」の基盤にする構成です。

### 実装のポイント：2段階のロック管理

1分に1回動くため、処理が重なった際の「二重送信」を防ぐ必要があります。

1. **Tursoでのロック（排他制御）:**
* 処理開始時に Turso の `ai_processing_log` テーブルに `status='processing'` を書き込みます。
* `WHERE status != 'processing'` の条件で取得することで、他セッションが同じポストを触るのを防ぎます。


2. **ステータス遷移:**
* 未実施 → 処理中 (FastAPIがTursoを更新) → AI結果受領 (Tursoに一時保存) → ユーザー確認 (UIからSupabaseへ反映)



---

## 3. 追加要件への対応

* **メール通知:** FastAPIから **Resend** や **SendGrid** のAPIを叩くのが最も簡単です。週次分析が終わったタイミングで1通送るだけなら、これらのサービスの無料枠で十分対応可能です。
* **週次分析（特記事項の抽出）:**
* 日次の「整形」とは別に、週に一度だけ動くエンドポイント（`/weekly-summary`）を Cloud Scheduler で別途設定します。
* 過去7日分のポストをまとめて取得し、Google AI Studioに「この1週間の傾向は？」と投げ、結果を Turso の別テーブルに保存します。



Renderで実績のあるテンプレートがあります。
これはGitHubに上げているので、ここから、
CloudRunように変更したいと考えています。

ローカルにクローン作製して、
別の名前にして、GitHubに上げる、
そのままテストとしてCloudRunにアップする流れを考えています。
名前は「BEZstv1」で作りたいです。
主な手順教えてください。


Remove-Item -Recurse -Force .git
git init
git add .
git commit -m "Initial commit for Cloud Run"
git remote add origin https://github.com/sickboy0001/BEZstv1.git
git push -u origin main

Github
https://github.com/sickboy0001/PFXDGRSbase